{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apple State Identifier\n",
    "\n",
    "Apple State Identifier is a convolutional neural network trained with pictures of good and rotten apples to predict how long a user's apple will be good for when stored in the refrigerator or in the pantry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qR714lX7Vm_y"
   },
   "source": [
    "# Importing\n",
    "\n",
    "Import the necessary packages to effectively run the Apple State Identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hOFYYVFkIk6e"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f1802f7ff798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import requests\n",
    "import torch\n",
    "import copy\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model\n",
    "import sklearn.neural_network\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FpFIu69-_-C"
   },
   "source": [
    "# Load Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define first a function called _resize_images(localpath, subpaths)_ where _localpath_ is the main path to the directory containing all data for good and rotten apples, and where _subpaths_ is a list of all subdirectories inside _localpath_. This function will resize all images to a uniform value of \"|insert-here|\", and will convert any non-RGB pictures to RGB. \n",
    "    \n",
    "After running this, two values will be returned: an X and a y, where X is a Numpy array containing the pictures in RGB mode, and where y is the label to indicate whether a picture is for a good or rotten apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define a default size and delete first for loop calculating average size.\n",
    "\n",
    "def resize_images(localpath, subpaths):\n",
    "    # to calc avg\n",
    "    sizes_x = np.array([], dtype='float32')\n",
    "    sizes_y = np.array([], dtype='float32')\n",
    "    targets = np.array([], dtype='int64')\n",
    "    \n",
    "    num_pics = 0\n",
    "    \n",
    "    for subpath in subpaths:\n",
    "        for file in os.listdir(localpath + subpath):\n",
    "            \n",
    "            if subpath == 'good/':\n",
    "                targets = np.append(1, targets)\n",
    "            elif subpath == 'bad/':\n",
    "                targets = np.append(0, targets)\n",
    "                \n",
    "            f_img = localpath+subpath+file\n",
    "            img = Image.open(f_img)\n",
    "            \n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "                img.save(f_img)\n",
    "                \n",
    "            sizes_x = np.append(img.size[0], sizes_x)\n",
    "            sizes_y = np.append(img.size[1], sizes_y)\n",
    "            num_pics = num_pics + 1\n",
    "    \n",
    "    avg_x = int(np.average(sizes_x))\n",
    "    avg_y = int(np.average(sizes_y))\n",
    "    \n",
    "    all_pics_resized = np.zeros((num_pics, avg_y, avg_x, 3), dtype='int64')\n",
    "    \n",
    "    num_pics = 0\n",
    "    for subpath in subpaths:\n",
    "        for file in os.listdir(localpath + subpath):\n",
    "            f_img = localpath+subpath+file\n",
    "            img = Image.open(f_img)\n",
    "            img = img.resize((avg_x, avg_y))\n",
    "#             print(img.size)\n",
    "            all_pics_resized[num_pics] = img\n",
    "            num_pics = num_pics + 1\n",
    "    \n",
    "    return all_pics_resized.reshape(num_pics, avg_y, avg_x, 3), targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call our function _resize_images(localpath, subdirectories)_ defined above to obtain the data for the convnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main data directory\n",
    "f = r'data/'\n",
    "\n",
    "# Subdirectories\n",
    "f_good_apples = r'good/'\n",
    "f_bad_apples = r'bad/'\n",
    "\n",
    "X, y = resize_images(f, [f_good_apples, f_bad_apples])\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output right above tells us we have a total of 120 pictures (60 good, 60 rotten) of size |size| in mode RGB.\n",
    "\n",
    "Now, let us print one of our images to confirm that everything is going as intended so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(X[68]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: split training and testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our convolutional neural network to take in data, we have to convert our _X_ and _y_ from the section above to PyTorch objects. Note that for _X_ we clip the data in the range \\[0..1\\] because this way |insert reason|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_torch, y_torch = torch.tensor((X - np.amin(X)) / (np.amax(X) - np.amin(X)), dtype=torch.float32), torch.from_numpy(y)\n",
    "X_torch = X_torch.reshape(69, 3, 390, 453)\n",
    "\n",
    "\n",
    "# Preprocess all the data first\n",
    "# X_torch_all, y_torch_all = torch.tensor((X - np.amin(X)) / (np.amax(X) - np.amin(X)), dtype=torch.float32), torch.from_numpy(y)\n",
    "# X_torch_all = X_torch_all.reshape(100, 3, 390, 453)\n",
    "\n",
    "# Split into training and test\n",
    "# X_train_torch, X_test_torch, y_train_torch, y_test_torch  = sklearn.model_selection.train_test_split(X_torch_all, y_torch_all, train_size=0.7, random_state=0)\n",
    "\n",
    "\n",
    "print(X_torch.shape, y_torch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the model we follow to create the Apple State Identifier neural network is the following:\n",
    "- Feature learning\n",
    "  - Layer 1\n",
    "    - Convolutional 2D layer\n",
    "    - ReLU activation\n",
    "    - MaxPooling\n",
    "\n",
    "  - Layer 2\n",
    "    - Convolutional 2D layer\n",
    "    - ReLU activation\n",
    "    \n",
    "- Classification\n",
    "  - Flatten\n",
    "  - Fully Connected (TODO: missing. Can be set up through loss)\n",
    "  - Linear\n",
    "  \n",
    "  \n",
    "The reason we have this setup is because |insert reason|\n",
    "\n",
    "Moreover, our options are:\n",
    "- Number of filters: \n",
    "- Filter size:\n",
    "- Bias: \n",
    "- Padding: \n",
    "- Stride: \n",
    "  \n",
    "Let us proceed to code this:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "num_filters = 8\n",
    "filter_size = 5\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, num_filters, padding=filter_size//2, kernel_size=filter_size, stride=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    torch.nn.Conv2d(8, num_filters, kernel_size=filter_size, stride=1),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(109 * 93 * num_filters, 2)\n",
    ")\n",
    "\n",
    "output = model(X_torch)\n",
    "# output = model(X_train_torch)\n",
    "\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: does it make sense to have this below? The epoch run will do this same thing but hundreds of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.softmax(model(X_torch[:69]), dim=1)\n",
    "# y_pred = torch.softmax(model(X_test_torch[:15]), dim=1)\n",
    "print(y_pred)\n",
    "\n",
    "y_true = torch.zeros((69, 2))\n",
    "y_true[torch.arange(69), y_torch[:69]] = 1\n",
    "# y_true_test = torch.zeros((15, 2))\n",
    "# y_true_test[torch.arange(15), y_test_torch[:15]] = 1\n",
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model we want, we give it our training data to train it. Since we have a binary classification problem (good or rotten), we use torch.nn.BCEWithLogitsLoss() which will make our model fully connected.\n",
    "\n",
    "Also, let us we set a high epoch and print our training loss for each one to see how well the model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = copy.deepcopy(untrained_model)\n",
    "\n",
    "# The number of times to evaluate the full training data (in this case, number of gradient steps)\n",
    "num_epoch = 50\n",
    "\n",
    "# Your code for defining loss, optimizer, and training loop here. Aim for 10-12 lines.\n",
    "\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.001)\n",
    "\n",
    "for epoch in range(1, num_epoch+1):\n",
    "    y_pred = model(X_torch)\n",
    "    loss_value = loss(y_pred, y_true)\n",
    "#     y_pred = model(X_train_torch)\n",
    "#     loss_value = loss(y_pred, y_true_test)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch == 1 or epoch % 10 == 0:\n",
    "        print(\"Epoch %d had training loss %.4f\" % (epoch, loss_value.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "We now know we have a working network and what its loss is for multiple epoch runs, but what else could we look at?\n",
    "\n",
    "Something extremely important is the overall accuracy of the model, and the stats for each category.\n",
    "\n",
    "Below, for our testing set, we can see the label of each picture (left) and how it was classified (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7f33533fed57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_true_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# y_true_index = torch.tensor([torch.argmax(y_true_test[i]) for i in range(len(y_true_test))])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "y_true_index = torch.tensor([torch.argmax(y_true[i]) for i in range(len(y_true))])\n",
    "# y_true_index = torch.tensor([torch.argmax(y_true_test[i]) for i in range(len(y_true_test))])\n",
    "y_pred_index = torch.tensor([torch.argmax(y_pred[i]) for i in range(len(y_pred))])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(121).set_title(\"True Values\")\n",
    "plt.scatter(np.arange(len(X_torch)), y_true_index, c='r', marker='o')\n",
    "# plt.scatter(np.arange(len(X_test_torch)), y_true_index, c='r', marker='o')\n",
    "plt.xlabel(\"Picture Number\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.yticks((0,1))\n",
    "\n",
    "plt.subplot(122).set_title(\"Predicted Values\")\n",
    "plt.scatter(np.arange(len(X_torch)), y_pred_index, c='b', marker='x')\n",
    "# plt.scatter(np.arange(len(X_test_torch)), y_true_index, c='r', marker='o')\n",
    "plt.xlabel(\"Picture Number\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.yticks((0,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting way of looking at the results is using Lab 9's _plot_named_tensors(tensor_dict)_. The colorbars below graphically tell us an overall picture of how the classification went for our testing data.\n",
    "\n",
    "Credit: Andrew Delong, Lab 9, COMP 432 Fall 2020 Concordia University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_named_tensors(tensor_dict):\n",
    "    \"\"\"\n",
    "    Given a dict of {name: tensor} pairs, plots the tensors side-by-side in a common\n",
    "    color scale. The name of each tensor is shown above its plot.\n",
    "    \"\"\"\n",
    "    n = len(tensor_dict)\n",
    "    vmax = max(v.abs().max() for v in tensor_dict.values())\n",
    "    figsize = (2*n, 6)\n",
    "    fig, axes = plt.subplots(1, n, figsize=figsize,  constrained_layout=True, squeeze=True)\n",
    "    axes = axes.flat if isinstance(axes, np.ndarray) else (axes,)\n",
    "    for (name, v), ax in zip(tensor_dict.items(), axes):\n",
    "        v = torch.squeeze(v.detach())   # Automatically convert (N,1,D) to (N,D)\n",
    "        if v.ndim == 1:\n",
    "            v = v.view(-1, 1)  # Automatically convert (N,) to (N,1)\n",
    "        assert v.ndim == 2, \"couldn't turn tensors[%d] with shape %s into 2D\" % (i, v.shape)\n",
    "        img = ax.matshow(v, vmin=0, vmax=1, cmap=plt.get_cmap('bwr'))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title(name)\n",
    "    fig.colorbar(img, cax=fig.add_axes([0.985, 0.25, 0.03, .5]))   # Add a colorbar on the right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_named_tensors({'y_pred' : y_pred, 'y_true': y_true})\n",
    "# plot_named_tensors({'y_pred' : y_pred, 'y_true': y_true_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: print accuracies in percentages like in video\n",
    "\n",
    "Numerically speaking, these are the values we are seeing above:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: refactor code below into function\n",
    "\n",
    "For this section we will visualize how each layer in our network is scoring each area of the pictures in our training data set; therefore, as reference, let us show 3 good apples and 3 bad ones from this group of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "\n",
    "plt.subplot(161)\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(X_torch[0].reshape(390,453,3));\n",
    "# plt.imshow(X_test_torch[0].reshape(390,453,3));\n",
    "\n",
    "\n",
    "plt.subplot(162)\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(X_torch[60].reshape(390,453,3));\n",
    "# plt.imshow(X_test_torch[60].reshape(390,453,3));\n",
    "\n",
    "\n",
    "plt.subplot(163)\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(X_torch[5].reshape(390,453,3));\n",
    "# plt.imshow(X_test_torch[5].reshape(390,453,3));\n",
    "\n",
    "\n",
    "plt.subplot(164)\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(X_torch[57].reshape(390,453,3));\n",
    "# plt.imshow(X_test_torch[57].reshape(390,453,3));\n",
    "\n",
    "\n",
    "plt.subplot(165)\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(X_torch[15].reshape(390,453,3));\n",
    "# plt.imshow(X_test_torch[15].reshape(390,453,3));\n",
    "\n",
    "plt.subplot(166)\n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.imshow(X_torch[40].reshape(390,453,3));\n",
    "# plt.imshow(X_test_torch[40].reshape(390,453,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the _plot_matrix_grid(V)_ to visually analyze a filter's weights.\n",
    "\n",
    "Credit: Andrew Delong, Lab 9, COMP 432 Fall 2020 Concordia University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_grid(V, cmap='bwr'):\n",
    "    \"\"\"\n",
    "    Given an array V containing stacked matrices, plots them in a grid layout.\n",
    "    V should have shape (K,M,N) where V[k] is a matrix of shape (M,N).\n",
    "    The default cmap is \"bwr\" (blue-white-red) but can also be \"gray\".\n",
    "    \"\"\"\n",
    "    if isinstance(V, torch.Tensor):\n",
    "        V = V.detach().numpy()\n",
    "    assert V.ndim == 3, \"Expected V to have 3 dimensions, not %d\" % V.ndim\n",
    "    k, m, n = V.shape\n",
    "    ncol = 8                                     # At most 8 columns\n",
    "    nrow = min(4, (k + ncol - 1) // ncol)        # At most 4 rows\n",
    "    V = V[:nrow*ncol]                            # Focus on just the matrices we'll actually plot\n",
    "    figsize = (2*ncol, max(1, 2*nrow*(m/n)))     # Guess a good figure shape based on ncol, nrow\n",
    "    fig, axes = plt.subplots(nrow, ncol, sharex=True, sharey=True, figsize=figsize)\n",
    "    vmax = np.percentile(np.abs(V), [99.9])      # Show the main range of values, between 0.1%-99.9%\n",
    "    for v, ax in zip(V, axes.flat):\n",
    "        img = ax.matshow(v, vmin=-vmax, vmax=vmax, cmap=plt.get_cmap(cmap))\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    for ax in axes.flat[len(V):]:\n",
    "        ax.set_axis_off()\n",
    "    fig.colorbar(img, cax=fig.add_axes([0.92, 0.25, 0.01, .5]))   # Add a colorbar on the right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First layer filter weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1, b1, W2, b2, W3, b3 = model.parameters()\n",
    "\n",
    "plot_matrix_grid(W1.reshape(12,5,5), cmap='bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second layer filter weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix_grid(W2.reshape(16,5,5), cmap='bwr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How long will my apple last?\n",
    "\n",
    "Since we have trained, tested and verified the results of our convnet, we can proceed to achieve the goal that was set at the beginning: to determine how long a user's apple has left in the refrigerator or in the pantry.\n",
    "\n",
    "The first thing we will do is create a map that will match the predicted score of a given apple as a good apple to a number of days. These days represent how long said apple will last in the refrigerator. Later on we will repeat the process but for when storing the apple in the pantry.\n",
    "\n",
    "Sources for an apple's live before it becomes rotten:\n",
    "- HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create classification map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our map, let us load an apple we are interested in knowing how long it has left before going bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load apple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, run this apple though the convnet to obtain a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: obtain prediction from neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass this prediction to the map and obtain a result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Pass this prediction to the map and obtain a result!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Apple State Identifier",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
